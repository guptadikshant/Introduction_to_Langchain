{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "58182813",
   "metadata": {},
   "source": [
    "# Langchain Documentation ChatBot"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "fd98dc17",
   "metadata": {},
   "source": [
    "* Scenario:- \n",
    "    These days there is a hype around building LLM powered Applications. Many of your competitors have already gained a headstart in this race. Now you wish to catch up on them by training your fellow collegues on \"Langchain\" which is a framework that helps build LLM powered apps swiftly. \n",
    "'\\n'\n",
    "* Question:- \n",
    "    \n",
    "    The requirement here is to build a chatbot that knows \"LangChain\" documention. Which can be then utilized by anyone in the org to learn Langchain! For this purpose, you should implement the following things:-\n",
    "\n",
    "    1. Setup Pinecone, create an index with dim=1536, metric=euclidean & get API Key by singing up on https://www.pinecone.io/\n",
    "    2. Download Langchian doumention from Prelude section.\n",
    "    3. Load the Documention using \"ReadTheDocsLoader\"\n",
    "    4. Use \"RecursiveCharacterTextSplitter\" to makes chunks of the loaded documents (chunk size=2000, overlap=200)\n",
    "    5. Create Embedding Model out of OpenAIEmbedding\n",
    "    6. Upload all vectors to Pinecone unsing the Pinecone class\n",
    "    7. Create a Chatbot using \"retrivalQA\" CHain\n",
    "    8. Implement Chat history using 'ConversationBufferMemory' & 'ConversationalRetrievalChain'\n",
    "    \n",
    "* Optional:-\n",
    "    9. Create 2 tools one out of vector store & a SerpAPI tool\n",
    "    10. Refer the documentation and try to Immplement the same by using above tools & chatbot Agent"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "b28aa92b",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\anikesh.mane\\AppData\\Local\\Temp\\ipykernel_52312\\431272371.py:3: TqdmWarning: IProgress not found. Please update jupyter and ipywidgets. See https://ipywidgets.readthedocs.io/en/stable/user_install.html\n",
      "  from tqdm.autonotebook import tqdm\n"
     ]
    }
   ],
   "source": [
    "import os\n",
    "from typing import Any, Dict, List\n",
    "from tqdm.autonotebook import tqdm\n",
    "\n",
    "from langchain.document_loaders import ReadTheDocsLoader\n",
    "\n",
    "from langchain.text_splitter import RecursiveCharacterTextSplitter\n",
    "\n",
    "from langchain.embeddings import OpenAIEmbeddings\n",
    "\n",
    "from langchain.chat_models import ChatOpenAI\n",
    "from langchain.chains import ConversationalRetrievalChain\n",
    "from langchain.chains import RetrievalQA\n",
    "\n",
    "from langchain.vectorstores import Pinecone\n",
    "import pinecone"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "0b844d39",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "686908a0",
   "metadata": {},
   "outputs": [],
   "source": [
    "PINECONE_API_KEY = '949f2f93-931e-41ff-80b9-72ad5e6b6dac'\n",
    "PINECONE_ENVIRONMENT_REGION = 'asia-southeast1-gcp-free'\n",
    "OPENAI_API_KEY = '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'"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "956b918d",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "129ababc",
   "metadata": {},
   "outputs": [],
   "source": [
    "pinecone.init(\n",
    "    api_key= PINECONE_API_KEY,\n",
    "    environment= PINECONE_ENVIRONMENT_REGION,\n",
    ")\n",
    "\n",
    "INDEX_NAME = \"langchain-doc-index\""
   ]
  },
  {
   "cell_type": "markdown",
   "id": "88144e48",
   "metadata": {},
   "source": [
    "## Load Data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "eef3908a",
   "metadata": {},
   "outputs": [],
   "source": [
    "loader = ReadTheDocsLoader(path=\"api.python.langchain.com/en/latest\",encoding=\"ISO-8859-1\",features=\"lxml\")\n",
    "\n",
    "raw_documents = loader.load()\n",
    "print(f\"loaded {len(raw_documents)} documents\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "b87f1a39",
   "metadata": {},
   "source": [
    "## Create Embedding into Pinecone"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "110af172",
   "metadata": {},
   "outputs": [],
   "source": [
    "text_splitter = RecursiveCharacterTextSplitter(\n",
    "    chunk_size=2000, chunk_overlap=200, separators=[\"\\n\\n\", \"\\n\", \" \", \"\"]\n",
    ")\n",
    "\n",
    "documents = text_splitter.split_documents(raw_documents)\n",
    "\n",
    "print(f\"Splitted into {len(documents)} chunks\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "9168599c",
   "metadata": {},
   "outputs": [],
   "source": [
    "print(documents[0].metadata[\"source\"])\n",
    "\n",
    "for doc in documents:\n",
    "    new_url = doc.metadata[\"source\"]\n",
    "    new_url = \"https:/\" + new_url\n",
    "    doc.metadata.update({\"source\": new_url})\n",
    "    \n",
    "print(documents[0].metadata[\"source\"])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "8b3551c3",
   "metadata": {},
   "outputs": [],
   "source": [
    "embeddings = OpenAIEmbeddings(openai_api_key=OPENAI_API_KEY)\n",
    "print(f\"Going to add {len(documents)} to Pinecone\")\n",
    "\n",
    "Pinecone.from_documents(documents, embeddings, index_name=INDEX_NAME)\n",
    "print(\"****Loading to vectorestore done ***\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "4cdec53d",
   "metadata": {},
   "source": [
    "## Make the ChatBot"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "80d5322a",
   "metadata": {},
   "outputs": [],
   "source": [
    "embeddings = OpenAIEmbeddings(openai_api_key=OPENAI_API_KEY)\n",
    "\n",
    "docsearch = Pinecone.from_existing_index(embedding=embeddings,\n",
    "                                         index_name=INDEX_NAME\n",
    "                                        )\n",
    "\n",
    "chat = ChatOpenAI(openai_api_key=OPENAI_API_KEY,\n",
    "                  verbose=True,\n",
    "                  temperature=0\n",
    "                 )"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "id": "cb91f621",
   "metadata": {},
   "outputs": [],
   "source": [
    "qa = RetrievalQA.from_chain_type(llm=chat, \n",
    "                                 chain_type=\"stuff\", \n",
    "                                 retriever=docsearch.as_retriever(),\n",
    "                                 verbose=True,\n",
    "                                 return_source_documents=True\n",
    "                                )"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 84,
   "id": "d315edd5",
   "metadata": {},
   "outputs": [],
   "source": [
    "query = 'What is Langchain?'\n",
    "query1 = 'which chain can be used to create a chatbot with Langchain?'\n",
    "query2 = 'Can you give an explain it with an example?'\n",
    "query3 = 'What are huggingface transformer agents?'"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 121,
   "id": "79444602",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "\n",
      "\u001b[1m> Entering new  chain...\u001b[0m\n",
      "\n",
      "\u001b[1m> Finished chain.\u001b[0m\n"
     ]
    }
   ],
   "source": [
    "output = qa({\"query\": query})"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 122,
   "id": "85e747be",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Langchain Agents are software programs that use artificial intelligence to understand and respond to human language. They are designed to perform specific tasks or provide information based on the user's input.\n",
      "\n",
      "For example, let's say you have a language learning app called Langchain. You want to improve the user experience and integrate it with other products that users might find useful. You can use Langchain Agents to achieve this.\n",
      "\n",
      "One Langchain Agent can be responsible for improving the app's interfaces and user experience. It can analyze user feedback and make changes to make the app more user-friendly.\n",
      "\n",
      "Another Langchain Agent can be responsible for integrating the app with other products, such as translation services or language practice tools. It can communicate with these external services and provide seamless integration for the users.\n",
      "\n",
      "By using Langchain Agents, you can automate and enhance various aspects of your app, making it more efficient and user-friendly. These agents can handle different tasks simultaneously, making your app more powerful and versatile.\n",
      "\n",
      "In simple terms, Langchain Agents are like smart assistants that understand and respond to human language, helping to improve and enhance your language learning app.\n"
     ]
    }
   ],
   "source": [
    "print(output['result'])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "id": "0f0cd852",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "4\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "Document(page_content='langchain.llms.deepinfra\\nlangchain.llms.fake\\nlangchain.llms.forefrontai\\nlangchain.llms.google_palm\\nlangchain.llms.gooseai\\nlangchain.llms.gpt4all\\nlangchain.llms.huggingface_endpoint\\nlangchain.llms.huggingface_hub\\nlangchain.llms.huggingface_pipeline\\nlangchain.llms.huggingface_text_gen_inference\\nlangchain.llms.human\\nlangchain.llms.koboldai\\nlangchain.llms.llamacpp\\nlangchain.llms.loading\\nlangchain.llms.manifest\\nlangchain.llms.modal\\nlangchain.llms.mosaicml\\nlangchain.llms.nlpcloud\\nlangchain.llms.octoai_endpoint\\nlangchain.llms.openai\\nlangchain.llms.openllm\\nlangchain.llms.openlm\\nlangchain.llms.petals\\nlangchain.llms.pipelineai\\nlangchain.llms.predictionguard\\nlangchain.llms.promptlayer_openai\\nlangchain.llms.replicate\\nlangchain.llms.rwkv\\nlangchain.llms.sagemaker_endpoint\\nlangchain.llms.self_hosted\\nlangchain.llms.self_hosted_hugging_face\\nlangchain.llms.stochasticai\\nlangchain.llms.textgen\\nlangchain.llms.tongyi\\nlangchain.llms.utils\\nlangchain.llms.vertexai\\nlangchain.llms.writer\\nlangchain.load.dump\\nlangchain.load.load\\nlangchain.load.serializable\\nlangchain.math_utils\\nlangchain.memory.buffer\\nlangchain.memory.buffer_window\\nlangchain.memory.chat_memory\\nlangchain.memory.chat_message_histories.cassandra\\nlangchain.memory.chat_message_histories.cosmos_db\\nlangchain.memory.chat_message_histories.dynamodb\\nlangchain.memory.chat_message_histories.file\\nlangchain.memory.chat_message_histories.firestore\\nlangchain.memory.chat_message_histories.in_memory\\nlangchain.memory.chat_message_histories.momento\\nlangchain.memory.chat_message_histories.mongodb\\nlangchain.memory.chat_message_histories.postgres\\nlangchain.memory.chat_message_histories.redis\\nlangchain.memory.chat_message_histories.sql\\nlangchain.memory.chat_message_histories.zep\\nlangchain.memory.combined\\nlangchain.memory.entity\\nlangchain.memory.kg\\nlangchain.memory.motorhead_memory\\nlangchain.memory.readonly\\nlangchain.memory.simple\\nlangchain.memory.summary\\nlangchain.memory.summary_buffer\\nlangchain.memory.token_buffer\\nlangchain.memory.utils', metadata={'source': 'https:/api.python.langchain.com\\\\en\\\\latest\\\\_modules\\\\index.html'})"
      ]
     },
     "execution_count": 15,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "print(len(output['source_documents']))\n",
    "\n",
    "output['source_documents'][0]"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "ca689e79",
   "metadata": {},
   "source": [
    "## Adding Chat History (memory)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "id": "54b06346",
   "metadata": {},
   "outputs": [],
   "source": [
    "from langchain.chains.conversation.memory import ConversationBufferMemory"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 29,
   "id": "55e745b7",
   "metadata": {},
   "outputs": [],
   "source": [
    "chat_history = ConversationBufferMemory(memory_key=\"chat_history\", return_messages=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 34,
   "id": "0be4c756",
   "metadata": {},
   "outputs": [],
   "source": [
    "conv_qa = ConversationalRetrievalChain.from_llm(llm=chat,\n",
    "                                                retriever=docsearch.as_retriever(), \n",
    "                                                memory=chat_history\n",
    "                                               )"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 37,
   "id": "a61eec6e",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "{'question': 'Can you give an explain it with an example?',\n",
       " 'chat_history': [HumanMessage(content='which chain can be used to create a chatbot with Langchain?', additional_kwargs={}, example=False),\n",
       "  AIMessage(content='The \"langchain.chains.conversation.base\" chain can be used to create a chatbot with Langchain.', additional_kwargs={}, example=False),\n",
       "  HumanMessage(content='Can you give an explain it with an example?', additional_kwargs={}, example=False),\n",
       "  AIMessage(content='Sure! The \"langchain.chains.conversation.base\" chain is used to create a chatbot with Langchain. Here\\'s an example to explain how it can be used:\\n\\n```python\\nfrom langchain.chains.conversation.base import ConversationChain\\n\\n# Create an instance of the ConversationChain\\nconversation_chain = ConversationChain()\\n\\n# Start the conversation loop\\nwhile True:\\n    # Get user input\\n    user_input = input(\"User: \")\\n\\n    # Pass the user input to the conversation chain\\n    response = conversation_chain(user_input)\\n\\n    # Print the bot\\'s response\\n    print(\"Bot:\", response)\\n```\\n\\nIn this example, we create an instance of the ConversationChain class and start a conversation loop. Inside the loop, we get user input using the `input()` function and pass it to the conversation chain using the `conversation_chain()` method. The conversation chain processes the user input and generates a response, which we then print as the bot\\'s response.\\n\\nYou can customize the behavior of the conversation chain by modifying its configuration or by extending its functionality with additional chains or modules.\\n\\nNote that this is a basic example, and you can add more complexity to the conversation loop based on your specific requirements.', additional_kwargs={}, example=False)],\n",
       " 'answer': 'Sure! The \"langchain.chains.conversation.base\" chain is used to create a chatbot with Langchain. Here\\'s an example to explain how it can be used:\\n\\n```python\\nfrom langchain.chains.conversation.base import ConversationChain\\n\\n# Create an instance of the ConversationChain\\nconversation_chain = ConversationChain()\\n\\n# Start the conversation loop\\nwhile True:\\n    # Get user input\\n    user_input = input(\"User: \")\\n\\n    # Pass the user input to the conversation chain\\n    response = conversation_chain(user_input)\\n\\n    # Print the bot\\'s response\\n    print(\"Bot:\", response)\\n```\\n\\nIn this example, we create an instance of the ConversationChain class and start a conversation loop. Inside the loop, we get user input using the `input()` function and pass it to the conversation chain using the `conversation_chain()` method. The conversation chain processes the user input and generates a response, which we then print as the bot\\'s response.\\n\\nYou can customize the behavior of the conversation chain by modifying its configuration or by extending its functionality with additional chains or modules.\\n\\nNote that this is a basic example, and you can add more complexity to the conversation loop based on your specific requirements.'}"
      ]
     },
     "execution_count": 37,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "conv_qa({\"question\": query2})"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 39,
   "id": "4497074b",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "[HumanMessage(content='which chain can be used to create a chatbot with Langchain?', additional_kwargs={}, example=False),\n",
       " AIMessage(content='The \"langchain.chains.conversation.base\" chain can be used to create a chatbot with Langchain.', additional_kwargs={}, example=False),\n",
       " HumanMessage(content='Can you give an explain it with an example?', additional_kwargs={}, example=False),\n",
       " AIMessage(content='Sure! The \"langchain.chains.conversation.base\" chain is used to create a chatbot with Langchain. Here\\'s an example to explain how it can be used:\\n\\n```python\\nfrom langchain.chains.conversation.base import ConversationChain\\n\\n# Create an instance of the ConversationChain\\nconversation_chain = ConversationChain()\\n\\n# Start the conversation loop\\nwhile True:\\n    # Get user input\\n    user_input = input(\"User: \")\\n\\n    # Pass the user input to the conversation chain\\n    response = conversation_chain(user_input)\\n\\n    # Print the bot\\'s response\\n    print(\"Bot:\", response)\\n```\\n\\nIn this example, we create an instance of the ConversationChain class and start a conversation loop. Inside the loop, we get user input using the `input()` function and pass it to the conversation chain using the `conversation_chain()` method. The conversation chain processes the user input and generates a response, which we then print as the bot\\'s response.\\n\\nYou can customize the behavior of the conversation chain by modifying its configuration or by extending its functionality with additional chains or modules.\\n\\nNote that this is a basic example, and you can add more complexity to the conversation loop based on your specific requirements.', additional_kwargs={}, example=False)]"
      ]
     },
     "execution_count": 39,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "conv_qa.memory.buffer"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "9cee3953",
   "metadata": {},
   "source": [
    "## Adding Tools and Agents"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 71,
   "id": "70914d99",
   "metadata": {},
   "outputs": [],
   "source": [
    "from langchain.llms import OpenAI\n",
    "from langchain.agents import initialize_agent, Tool\n",
    "from langchain.agents import AgentType\n",
    "from langchain.utilities import SerpAPIWrapper"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 58,
   "id": "665b69f0",
   "metadata": {},
   "outputs": [],
   "source": [
    "SERPAPI_API_KEY = '12d80712d6c6183ba8817c6bb3b896c5de3c37277d7398e6bbb33a15f74d550a'"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 63,
   "id": "c8e57475",
   "metadata": {},
   "outputs": [],
   "source": [
    "search = SerpAPIWrapper(serpapi_api_key=SERPAPI_API_KEY)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 62,
   "id": "e5332ed4",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "'Hugging Face, Inc. is an American company that develops tools for building applications using machine learning. It is most notable for its transformers library built for natural language processing applications and its platform that allows users to share machine learning models and datasets.'"
      ]
     },
     "execution_count": 62,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "search.run(\"what is huggingFace?\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 74,
   "id": "6757a0ab",
   "metadata": {},
   "outputs": [],
   "source": [
    "retrieval_qa = RetrievalQA.from_chain_type(llm=chat, \n",
    "                                           chain_type=\"stuff\", \n",
    "                                           retriever=docsearch.as_retriever()\n",
    "                                          )"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 75,
   "id": "aed4d836",
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "tools = [\n",
    "    Tool(\n",
    "        name=\"Langchain Documentation QA System\",\n",
    "        func=retrieval_qa.run,\n",
    "        description=\"useful for when you need to answer questions about the Langchain, which is a framework to build LLM powered applications.The 'Index name' to be used is 'langchain-doc-index'.chroma/ \"\n",
    "    ),\n",
    "    Tool(\n",
    "        name=\"search\",\n",
    "        func=search.run,\n",
    "        description=\"useful for when you need to answer questions about current events or need to do a web search.\",\n",
    "    ),\n",
    "]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 82,
   "id": "c9d1fbe2",
   "metadata": {},
   "outputs": [],
   "source": [
    "llm = OpenAI(temperature=0, openai_api_key=OPENAI_API_KEY)\n",
    "\n",
    "agent = initialize_agent(\n",
    "    tools, llm, agent=AgentType.ZERO_SHOT_REACT_DESCRIPTION, verbose=True\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 120,
   "id": "79c1737d",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "\n",
      "\u001b[1m> Entering new  chain...\u001b[0m\n",
      "\u001b[32;1m\u001b[1;3m OpenAI Plugins are a set of tools that allow developers to quickly and easily integrate OpenAI models into their applications.\n",
      "Action: Langchain Documentation QA System\n",
      "Action Input: OpenAI Plugins\u001b[0m\n",
      "Observation: \u001b[36;1m\u001b[1;3mThere is no specific information available about OpenAI Plugins in the given context.\u001b[0m\n",
      "Thought:\u001b[32;1m\u001b[1;3m I should search for more information.\n",
      "Action: search\n",
      "Action Input: OpenAI Plugins\u001b[0m\n",
      "Observation: \u001b[33;1m\u001b[1;3mPlugins are tools designed specifically for language models with safety as a core principle, and help ChatGPT access up-to-date information, run ...\u001b[0m\n",
      "Thought:\u001b[32;1m\u001b[1;3m I now know the final answer.\n",
      "Final Answer: OpenAI Plugins are tools designed specifically for language models with safety as a core principle, and help ChatGPT access up-to-date information, run tasks, and more.\u001b[0m\n",
      "\n",
      "\u001b[1m> Finished chain.\u001b[0m\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "'OpenAI Plugins are tools designed specifically for language models with safety as a core principle, and help ChatGPT access up-to-date information, run tasks, and more.'"
      ]
     },
     "execution_count": 120,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "agent.run(\"Explain OpenAI Plugins?\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 87,
   "id": "723dc2ce",
   "metadata": {},
   "outputs": [],
   "source": [
    "memory = ConversationBufferMemory(memory_key=\"chat_history\")\n",
    "\n",
    "conv_agent = initialize_agent(tools=tools,\n",
    "                              llm=llm, \n",
    "                              agent=AgentType.CONVERSATIONAL_REACT_DESCRIPTION, \n",
    "                              verbose=True, \n",
    "                              memory=memory\n",
    "                             )"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 88,
   "id": "4cdebeb0",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "\n",
      "\u001b[1m> Entering new  chain...\u001b[0m\n",
      "\u001b[32;1m\u001b[1;3m\n",
      "Thought: Do I need to use a tool? Yes\n",
      "Action: Langchain Documentation QA System\n",
      "Action Input: which chain can be used to create a chatbot with Langchain?\u001b[0m\n",
      "Observation: \u001b[36;1m\u001b[1;3mThe \"langchain.chains.conversation.base\" chain can be used to create a chatbot with Langchain.\u001b[0m\n",
      "Thought:\u001b[32;1m\u001b[1;3m Do I need to use a tool? No\n",
      "AI: You can use the \"langchain.chains.conversation.base\" chain to create a chatbot with Langchain.\u001b[0m\n",
      "\n",
      "\u001b[1m> Finished chain.\u001b[0m\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "'You can use the \"langchain.chains.conversation.base\" chain to create a chatbot with Langchain.'"
      ]
     },
     "execution_count": 88,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "conv_agent.run(query1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 89,
   "id": "a3205526",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "\n",
      "\u001b[1m> Entering new  chain...\u001b[0m\n",
      "\u001b[32;1m\u001b[1;3m\n",
      "Thought: Do I need to use a tool? No\n",
      "AI: Sure, here is an example of how to use the \"langchain.chains.conversation.base\" chain to create a chatbot. First, you need to define the conversation flow. This can be done by creating a list of questions and answers that the chatbot will use to interact with the user. Then, you need to define the logic of the conversation, such as how the chatbot will respond to certain inputs. Finally, you need to define the language model that will be used to generate the chatbot's responses. Once all of these components are in place, you can use the \"langchain.chains.conversation.base\" chain to create your chatbot.\u001b[0m\n",
      "\n",
      "\u001b[1m> Finished chain.\u001b[0m\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "'Sure, here is an example of how to use the \"langchain.chains.conversation.base\" chain to create a chatbot. First, you need to define the conversation flow. This can be done by creating a list of questions and answers that the chatbot will use to interact with the user. Then, you need to define the logic of the conversation, such as how the chatbot will respond to certain inputs. Finally, you need to define the language model that will be used to generate the chatbot\\'s responses. Once all of these components are in place, you can use the \"langchain.chains.conversation.base\" chain to create your chatbot.'"
      ]
     },
     "execution_count": 89,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "conv_agent.run(query2)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 104,
   "id": "1f516d81",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Human: which chain can be used to create a chatbot with Langchain?\n",
      "AI: You can use the \"langchain.chains.conversation.base\" chain to create a chatbot with Langchain.\n",
      "Human: Can you give an explain it with an example?\n",
      "AI: Sure, here is an example of how to use the \"langchain.chains.conversation.base\" chain to create a chatbot. First, you need to define the conversation flow. This can be done by creating a list of questions and answers that the chatbot will use to interact with the user. Then, you need to define the logic of the conversation, such as how the chatbot will respond to certain inputs. Finally, you need to define the language model that will be used to generate the chatbot's responses. Once all of these components are in place, you can use the \"langchain.chains.conversation.base\" chain to create your chatbot.\n"
     ]
    }
   ],
   "source": [
    "for msg in conv_agent.memory.buffer.split(sep='\\n'):\n",
    "    print(msg)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "674aad9c",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.11.3"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
